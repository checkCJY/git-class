import requests
# from urllib.parse import urlparse, parse_qs

# url = "https://google.com/search?q=python&page=2"

# parsed_url = urlparse(url)
# params = parse_qs(parsed_url.query)

# print("ì „ì²´ URL:", url)
# print("ê²½ë¡œ(Path):", parsed_url.path)
# print("ì¿¼ë¦¬(Query):", parsed_url.query)
# print("ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°:", params)



# urls = [
#     "https://google.com",                # 200 OK
#     "https://google.com/nonexist",       # 404 Not Found
#     "https://httpbin.org/status/500",    # 500 Internal Server Error
#     "https://httpbin.org/status/302"     # 302 Redirect
# ]

# for url in urls:
#     response = requests.get(url)
#     print(f"URL: {url}")
#     print("Status Code:", response.status_code)

#     if response.status_code == 200:
#         print("â†’ ì •ìƒì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤! ğŸ˜Š")
#     elif response.status_code == 404:
#         print("â†’ ì£¼ì†Œê°€ ì˜ëª»ë˜ì—ˆë‚˜ë´ìš”! ğŸ˜¢ í˜ì´ì§€ê°€ ì—†ì–´ìš”.")
#     elif response.status_code == 500:
#         print("â†’ ì„œë²„ê°€ ì•„íŒŒìš”! ê°œë°œìê°€ ê³ ì³ì•¼ í•´ìš” âš ï¸")
#     elif 300 <= response.status_code < 400:
#         print("â†’ ë‹¤ë¥¸ í˜ì´ì§€ë¡œ ì´ë™ì‹œí‚¤ê³  ìˆì–´ìš” ğŸ”")
    
#     print("-" * 50)

# # 1) ì–´ë–¤ ì£¼ì†Œì— ìš”ì²­ì„ ë³´ë‚¼ì§€ ì •í•œë‹¤.
# url = "https://www.naver.com"

# # 2) GET ìš”ì²­ ë³´ë‚´ê¸°
# # â†’ ë¸Œë¼ìš°ì €ì—ì„œ ì£¼ì†Œ ì…ë ¥í•˜ê³  Enter ì¹˜ëŠ” ê²ƒê³¼ ê±°ì˜ ê°™ë‹¤
# response = requests.get(url)

# # 3) ì‘ë‹µ ìƒíƒœ ì½”ë“œ í™•ì¸
# print("Status Code:", response.status_code)
# print("--- Response Text (ì•ë¶€ë¶„ë§Œ) ---")
# print(response.text[:300])   # ë„ˆë¬´ ê¸¸ì–´ì„œ ì• 300ê¸€ìë§Œ ì˜ë¼ì„œ ì¶œë ¥